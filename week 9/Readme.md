基于agent和observer的Q表探索出一条路径（states的集合），在该路径上时停止相互学习。

simulation系统则是在抵达fake goal前后使用不同的state。

基本稳定。
