使用广度优先搜索的方式让agent获得了一个检验功能，使agent在处于fake goal与real goal之间的一条最优路径内不会学习另一个agent的reward。
修改了遇到墙的处理方式，变为使agent在撞墙之后会在学习之前重新选择。
在可见的未来内，这个系统至少不会卡死在某个点了……
